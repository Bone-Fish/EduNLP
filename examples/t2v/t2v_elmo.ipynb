{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用ELMo向量化容器\n",
    "## 导入功能块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EduNLP.Pretrain import ElmoTokenizer\n",
    "from EduNLP.Vector import T2V, ElmoModel\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置你的数据路径和输出路径\n",
    "BASE_DIR = \"../..\"\n",
    "\n",
    "data_dir = f\"{BASE_DIR}/static/test_data\"\n",
    "output_dir = f\"{BASE_DIR}/examples/test_model/elmo/elmo_768\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 令牌化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seq_idx': tensor([ 804,   19,    6,   69,   26,   66, 1381,  804,    9,  254,   27,   69,\n",
      "          70,  246,   66,  239,    7]), 'seq_len': tensor(17)}\n",
      "\n",
      "{'seq_idx': tensor([[ 804,   19,    6,   69,   26,   66, 1381,  804,    9,  254,   27,   69,\n",
      "           70,  246,   66,  239,    7,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0],\n",
      "        [  64,  477,   69,   96,   81,   55,   82,   70,   66,   96,   81,   55,\n",
      "           82,   71,  467,   69,   27,   78,  844,   77,  477, 1312,  865,  519,\n",
      "          118]]), 'seq_len': tensor([17, 25])}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 加载之前训练的模型tokenizer\n",
    "tokenizer = ElmoTokenizer(os.path.join(output_dir, \"vocab.txt\"))\n",
    "\n",
    "# 对题目文本进行令牌化\n",
    "items = [\n",
    "    \"有公式$\\\\FormFigureID{wrong1?}$，如图$\\\\FigureID{088f15ea-xxx}$,\\\n",
    "    若$x,y$满足约束条件公式$\\\\FormFigureBase64{wrong2?}$,$\\\\SIFSep$，则$z=x+7 y$的最大值为$\\\\SIFBlank$\",\n",
    "    \"已知圆$x^{2}+y^{2}-6 x=0$，过点(1,2)的直线被该圆所截得的弦的长度的最小值为\"\n",
    "]\n",
    "\n",
    "# 可以对单个题目进行令牌化\n",
    "print(tokenizer(items[0], freeze_vocab=True))\n",
    "print()\n",
    "\n",
    "# 也可以对题目列表进行令牌化\n",
    "print(tokenizer(items, freeze_vocab=True))\n",
    "print()\n",
    "\n",
    "token_items = tokenizer(items, pad_to_max_length=True)\n",
    "_, lengths = token_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 向量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EduNLP, INFO] All the weights of ElmoLM were initialized from the model checkpoint at ../../examples/test_model/elmo/elmo_768.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ElmoLM for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElmoLMOutput([('pred_forward', tensor([[[-307.3449, -307.3120, -307.3644,  ..., -310.1035, -307.8653,\n",
      "          -305.8521],\n",
      "         [-278.2352, -278.3191, -278.3070,  ..., -278.2227, -277.5887,\n",
      "          -277.1101],\n",
      "         [-363.3187, -363.3951, -363.4167,  ..., -365.0335, -361.3292,\n",
      "          -363.0343],\n",
      "         ...,\n",
      "         [-283.5177, -283.5760, -283.6111,  ..., -284.5733, -282.6731,\n",
      "          -283.2103],\n",
      "         [-248.1853, -248.3669, -248.3075,  ..., -248.6257, -247.6015,\n",
      "          -247.8452],\n",
      "         [-241.4586, -241.4421, -241.4153,  ..., -240.6708, -240.4943,\n",
      "          -240.6182]],\n",
      "\n",
      "        [[-334.8899, -334.8294, -334.9643,  ..., -334.1731, -335.4581,\n",
      "          -334.7304],\n",
      "         [-355.3142, -355.3451, -355.4356,  ..., -356.5914, -352.9772,\n",
      "          -354.9101],\n",
      "         [-407.1169, -406.9889, -407.2259,  ..., -411.4367, -405.8418,\n",
      "          -407.2929],\n",
      "         ...,\n",
      "         [-330.3282, -330.3368, -330.3389,  ..., -332.7447, -331.5250,\n",
      "          -329.7366],\n",
      "         [-283.1005, -283.1692, -283.1745,  ..., -283.0395, -283.1997,\n",
      "          -282.8568],\n",
      "         [-235.8705, -235.7804, -235.8927,  ..., -235.1325, -235.2520,\n",
      "          -235.5008]]], grad_fn=<AddBackward0>)), ('pred_backward', tensor([[[-179.5577, -179.5323, -179.4542,  ..., -180.1722, -178.3642,\n",
      "          -178.2475],\n",
      "         [-344.9785, -344.9221, -345.0316,  ..., -349.3186, -344.6387,\n",
      "          -344.3976],\n",
      "         [-311.8071, -311.6877, -311.8076,  ..., -315.7125, -312.6975,\n",
      "          -311.0973],\n",
      "         ...,\n",
      "         [-164.1926, -164.2107, -164.1506,  ..., -164.0445, -162.9915,\n",
      "          -163.1473],\n",
      "         [-161.2745, -161.2983, -161.2401,  ..., -161.1260, -160.0812,\n",
      "          -160.0892],\n",
      "         [-201.1299, -201.1749, -201.0949,  ..., -200.5798, -200.0364,\n",
      "          -200.2121]],\n",
      "\n",
      "        [[-173.3366, -173.3426, -173.2081,  ..., -174.0968, -172.0103,\n",
      "          -171.8691],\n",
      "         [-310.7520, -310.6165, -310.7965,  ..., -313.6465, -312.9819,\n",
      "          -309.7775],\n",
      "         [-297.4435, -297.3187, -297.5530,  ..., -300.7402, -298.0805,\n",
      "          -296.7505],\n",
      "         ...,\n",
      "         [-365.5618, -365.3937, -365.5269,  ..., -369.6968, -367.3105,\n",
      "          -365.9371],\n",
      "         [-360.7122, -360.6502, -360.6949,  ..., -365.4681, -362.4482,\n",
      "          -358.9928],\n",
      "         [-328.2362, -328.2809, -328.2350,  ..., -331.3160, -328.4486,\n",
      "          -327.7178]]], grad_fn=<AddBackward0>)), ('forward_output', tensor([[[ 3.6525e-03,  2.2160e-02,  6.8173e-05,  ..., -4.7844e-03,\n",
      "           9.3836e-03, -4.3491e-01],\n",
      "         [ 1.8052e-02,  8.7361e-04,  4.8162e-01,  ..., -5.3586e-03,\n",
      "           6.6052e-02, -1.4424e-02],\n",
      "         [ 9.5443e-02,  1.6271e-02,  7.0382e-01,  ..., -8.3553e-03,\n",
      "           1.2897e-02, -3.1771e-02],\n",
      "         ...,\n",
      "         [ 5.2170e-03,  1.0105e-02,  2.6849e-01,  ..., -3.0296e-03,\n",
      "           1.4682e-01, -4.0381e-01],\n",
      "         [ 8.6507e-03,  1.2562e-02,  9.4650e-01,  ..., -1.0862e-03,\n",
      "           8.5297e-01, -2.2572e-01],\n",
      "         [ 3.1620e-02,  1.4642e-01,  1.0650e-01,  ..., -1.8507e-01,\n",
      "           3.6865e-04, -2.8440e-01]],\n",
      "\n",
      "        [[ 5.3534e-01,  2.1329e-02,  2.8222e-02,  ..., -7.0496e-02,\n",
      "           6.7711e-02, -3.1365e-03],\n",
      "         [ 5.6558e-02,  7.0860e-03,  4.0042e-01,  ..., -1.3037e-02,\n",
      "           2.2477e-02, -2.0711e-02],\n",
      "         [ 2.1927e-02,  4.2798e-01,  9.1026e-01,  ..., -1.8426e-01,\n",
      "           6.0737e-03, -1.7819e-01],\n",
      "         ...,\n",
      "         [ 3.7156e-02,  2.2477e-02,  6.9470e-01,  ..., -1.1230e-02,\n",
      "           1.1101e-02, -2.4664e-01],\n",
      "         [ 1.4176e-02,  1.6747e-02,  7.8785e-02,  ..., -1.8862e-02,\n",
      "           8.9409e-03, -6.1224e-01],\n",
      "         [ 7.9827e-02,  3.7614e-02,  2.8973e-01,  ..., -9.7911e-02,\n",
      "           2.5626e-04, -1.0576e-01]]], grad_fn=<SliceBackward0>)), ('backward_output', tensor([[[ 1.6726e-02,  1.6917e-02,  1.2608e-02,  ..., -1.1215e-02,\n",
      "          -7.0637e-01, -2.7572e-01],\n",
      "         [ 5.7128e-03,  4.2807e-02,  3.8698e-02,  ..., -1.0857e-03,\n",
      "          -7.1516e-01, -9.0976e-02],\n",
      "         [ 3.5365e-03,  2.8559e-02,  2.2622e-05,  ..., -3.7339e-03,\n",
      "           7.1600e-01, -5.7635e-01],\n",
      "         ...,\n",
      "         [ 4.6398e-02,  4.9136e-02,  1.2801e-02,  ..., -1.9671e-02,\n",
      "          -9.6720e-03, -9.6724e-02],\n",
      "         [ 4.0719e-02,  4.4131e-02,  1.2812e-02,  ..., -1.8923e-02,\n",
      "          -3.2772e-03, -8.6033e-02],\n",
      "         [ 4.6603e-02,  6.7548e-02,  3.4405e-02,  ..., -2.9001e-02,\n",
      "          -2.7431e-03, -1.3146e-01]],\n",
      "\n",
      "        [[ 2.9590e-02,  3.2132e-02,  1.8678e-02,  ..., -2.1314e-02,\n",
      "          -6.8087e-01, -6.1092e-02],\n",
      "         [ 1.8839e-03,  1.5880e-02,  4.3065e-03,  ..., -3.6674e-03,\n",
      "           7.4532e-01, -3.9937e-02],\n",
      "         [ 2.6377e-01,  6.6237e-03,  7.1997e-02,  ..., -2.2735e-02,\n",
      "           3.1916e-01, -1.1802e-02],\n",
      "         ...,\n",
      "         [ 6.5437e-01,  8.1936e-02,  8.6420e-01,  ..., -4.1453e-02,\n",
      "          -6.4451e-01, -1.3480e-01],\n",
      "         [ 1.7608e-01,  2.3962e-01,  8.7436e-01,  ..., -1.5172e-01,\n",
      "          -7.5390e-01, -2.2155e-01],\n",
      "         [ 8.7120e-02,  1.5658e-01,  7.4500e-01,  ..., -1.3044e-02,\n",
      "          -7.5951e-01, -3.6064e-01]]], grad_fn=<SliceBackward0>))])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\bdaa\\edunlp\\EduNLP\\Vector\\elmo_vec.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  (outputs.forward_output[torch.arange(len(items[\"seq_len\"])), torch.tensor(items[\"seq_len\"]) - 1],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 768])\n",
      "torch.Size([2, 25, 768])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t2v = ElmoModel(output_dir)\n",
    "\n",
    "# # 获得句表征\n",
    "i_vec = t2v(token_items)\n",
    "print(i_vec)\n",
    "print()\n",
    "\n",
    "# 获得句表征和词表征\n",
    "i_vec = t2v.infer_vector(token_items, lengths=lengths)\n",
    "t_vec = t2v.infer_tokens(token_items, lengths=lengths)\n",
    "print(i_vec.size())\n",
    "print(t_vec.size())\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "cc3e3b0a667322a868bdd200d76d82ed50310f7037715f6f0bc4c373c1c03ce5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
