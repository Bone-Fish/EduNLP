{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 区分度预估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-28 03:30:52.333651: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-06-28 03:30:52.381526: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-28 03:30:54.202449: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from transformers.modeling_outputs import ModelOutput\n",
    "from transformers import BertModel, TrainingArguments, Trainer, PretrainedConfig\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import ndcg_score, mean_squared_error\n",
    "from  torchmetrics import MeanAbsoluteError, PearsonCorrCoef, SpearmanCorrCoef\n",
    "import os\n",
    "import tqdm\n",
    "from EduNLP.Pretrain import BertTokenizer \n",
    "from EduNLP.ModelZoo.base_model import BaseModel\n",
    "import json\n",
    "from utils import  Dataset_bert, pre_disc\n",
    "\n",
    "ROOT = os.path.dirname(os.path.dirname(__file__))\n",
    "DATA_DIR = os.path.join(ROOT, \"data\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/shangzi/anaconda3/envs/tgen/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `SpearmanCorrcoef` will save all targets and predictions in the buffer. For large datasets, this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "MAE = MeanAbsoluteError()\n",
    "PCC = PearsonCorrCoef()\n",
    "SCC = SpearmanCorrCoef()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载数据，定义预训练模型路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.path.join(ROOT, \"output/discrimination\") #设置模型保存路径\n",
    "pretrained_model_dir = \"../data/bert_math_768\" #预训练的bert路径，也可以更换为其他模型的路径，如disenqnet, roberta等\n",
    "checkpoint_dir = \"path/to/difficulty_prediction_checkpoint\"\n",
    "train_items = pre_disc(os.path.join(DATA_DIR, \"train\", \"ctt_train.csv\")) #加载训练集\n",
    "val_items = pre_disc(os.path.join(DATA_DIR, \"test\", \"ctt_test.csv\")) #加载测试集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscriminationPredictionOutput(ModelOutput):\n",
    "    loss: torch.FloatTensor = None\n",
    "    logits: torch.FloatTensor = None\n",
    "    labels: torch.FloatTensor = None\n",
    "\n",
    "class BertForDiscriminationPrediction(BaseModel):\n",
    "    \n",
    "    def __init__(self, pretrained_model_dir=None, config=None, classifier_dropout=0.5):\n",
    "        super(BertForDiscriminationPrediction, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(pretrained_model_dir, ignore_mismatched_sizes=True) \n",
    "        hidden_size = self.bert.config.hidden_size\n",
    "        self.classifier_dropout = classifier_dropout\n",
    "        self.dropout = nn.Dropout(classifier_dropout)\n",
    "        self.classifier = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        self.config = {k: v for k, v in locals().items() if k not in [\"self\", \"__class__\"]}\n",
    "        self.config['architecture'] = 'BertForDiscriminationPrediction'\n",
    "        self.config = PretrainedConfig.from_dict(self.config)\n",
    "\n",
    "    def forward(self,\n",
    "                input_ids=None,\n",
    "                attention_mask=None,\n",
    "                token_type_ids=None,\n",
    "                content=None,\n",
    "                labels=None,\n",
    "                ):\n",
    "        \n",
    "        input_ids = content['input_ids']\n",
    "        attention_mask = content['attention_mask']\n",
    "        token_type_ids = content['token_type_ids'] \n",
    "        item_embed = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)['last_hidden_state'][:, 0, :]\n",
    "        logits = self.sigmoid(self.classifier(item_embed))\n",
    "        loss = F.mse_loss(logits.squeeze(0), labels)\n",
    "        return DiscriminationPredictionOutput(\n",
    "            loss = loss,\n",
    "            logits = logits,\n",
    "            labels = labels\n",
    "        )\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config_path, *args, **kwargs):\n",
    "        with open(config_path, \"r\", encoding=\"utf-8\") as rf:\n",
    "            model_config = json.load(rf)\n",
    "            model_config.update(kwargs)\n",
    "            return cls(\n",
    "                pretrained_model_dir=model_config['pretrained_model_dir'],\n",
    "                classifier_dropout=model_config.get(\"classifier_dropout\", 0.5),             \n",
    "            )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义评价指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    logits = torch.as_tensor(pred.predictions[0]).squeeze(0)\n",
    "    logits = logits.view([logits.size()[0]],-1)\n",
    "    labels = torch.as_tensor(pred.label_ids)\n",
    "    pres = logits.numpy().tolist()\n",
    "    golds = labels.numpy().tolist()\n",
    "    ret = {\n",
    "        \"mae\": MAE(logits, labels),\n",
    "        \"mse\": mean_squared_error(golds,  pres),\n",
    "        \"rmse\": np.sqrt(mean_squared_error(golds,  pres)),\n",
    "        \"pcc\": PCC(logits, labels),\n",
    "        \"scc\": SCC(logits, labels),\n",
    "        'ndcg': testdata_metrics(golds, pres).tolist(),\n",
    "    }\n",
    "    return ret\n",
    "\n",
    "def testdata_metrics(diff, pred):\n",
    "    diff, pred = np.array(diff), np.array(pred)\n",
    "    ndcg = []\n",
    "    ndcg.append([ndcg_score([diff], [pred]), ndcg_score([diff], [pred], k=10), ndcg_score([diff], [pred], k=20), ndcg_score([diff], [pred], k=30)])\n",
    "    ndcg = np.mean(ndcg, axis=0)\n",
    "    return ndcg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义训练和测试相关参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTrainer(Trainer):\n",
    "    pass\n",
    "\n",
    "def train_disc_pred(\n",
    "                        output_dir,\n",
    "                        pretrained_model_dir,\n",
    "                        train_items=None,\n",
    "                        val_items=None,\n",
    "                        train_params=None):\n",
    "    tokenizer = BertTokenizer.from_pretrained(pretrained_model_dir)\n",
    "    model = DiscriminationPredictionOutput(pretrained_model_dir=pretrained_model_dir) \n",
    "    model.bert.resize_token_embeddings(len(tokenizer.bert_tokenizer))\n",
    "  \n",
    "    if train_params is not None:\n",
    "        epochs = train_params['epochs'] if 'epochs' in train_params else 1\n",
    "        batch_size = train_params['batch_size'] if 'batch_size' in train_params else 64\n",
    "        save_steps = train_params['save_steps'] if 'save_steps' in train_params else 100\n",
    "        save_total_limit = train_params['save_total_limit'] if 'save_total_limit' in train_params else 2\n",
    "        logging_steps = train_params['logging_steps'] if 'logging_steps' in train_params else 5\n",
    "        gradient_accumulation_steps = train_params['gradient_accumulation_steps'] \\\n",
    "            if 'gradient_accumulation_steps' in train_params else 1\n",
    "        logging_dir = train_params['logging_dir'] if 'logging_dir' in train_params else f\"{ROOT}/log\"\n",
    "    else:\n",
    "        # default\n",
    "        epochs = 50\n",
    "        batch_size = 1\n",
    "        save_steps = 1000\n",
    "        save_total_limit = 2\n",
    "        logging_steps = 100\n",
    "        gradient_accumulation_steps = 1\n",
    "        logging_dir = f\"{ROOT}/log\"\n",
    "\n",
    "    train_dataset = Dataset_bert(train_items, tokenizer)\n",
    "    eval_dataset = Dataset_bert(val_items, tokenizer)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        overwrite_output_dir=True,\n",
    "\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        evaluation_strategy = \"steps\", # epoch\n",
    "        eval_steps=logging_steps*5,\n",
    "        \n",
    "        save_steps=save_steps,\n",
    "        save_total_limit=save_total_limit,\n",
    "        \n",
    "        logging_steps=logging_steps,\n",
    "        logging_dir=logging_dir,\n",
    "\n",
    "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "        learning_rate=5e-5,\n",
    "    )\n",
    "\n",
    "    trainer = MyTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        data_collator=train_dataset.collate_fn,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()      #训练模型\n",
    "    trainer.save_model(output_dir)\n",
    "    trainer.model.save_config(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)    #保存训练后的模型"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_disc_pred(\n",
    "        output_dir,\n",
    "        pretrained_model_dir=pretrained_model_dir,\n",
    "        train_items=train_items,\n",
    "        val_items=val_items,\n",
    "        train_params= None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 用于测试的网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscriminationPredictionEval(BaseModel): \n",
    "    def __init__(self, pretrained_model_dir=None, classifier_dropout=0.5):\n",
    "        super(DiscriminationPredictionEval, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(pretrained_model_dir, ignore_mismatched_sizes=True)\n",
    "        hidden_size = self.bert.config.hidden_size\n",
    "        self.classifier_dropout = classifier_dropout\n",
    "        self.dropout = nn.Dropout(classifier_dropout)\n",
    "        self.classifier = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        self.config = {k: v for k, v in locals().items() if k not in [\"self\", \"__class__\"]}\n",
    "        self.config['architecture'] = 'BertForDifficultyPrediction'\n",
    "        self.config = PretrainedConfig.from_dict(self.config)\n",
    "\n",
    "    def forward(self,\n",
    "                input_ids=None,\n",
    "                attention_mask=None,\n",
    "                token_type_ids=None,\n",
    "                ):\n",
    "\n",
    "        item_embed = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)['last_hidden_state'][:, 0, :]\n",
    "        logits = self.sigmoid(self.classifier(item_embed))\n",
    "        return logits\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config_path, **kwargs):\n",
    "        with open(config_path, \"r\", encoding=\"utf-8\") as rf:\n",
    "            model_config = json.load(rf)\n",
    "            model_config.update(kwargs)\n",
    "            return cls(\n",
    "                pretrained_model_dir=model_config['pretrained_model_dir'],\n",
    "                classifier_dropout=model_config.get(\"classifier_dropout\", 0.5),             \n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载测试集和模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvalDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, items, tokenizer):\n",
    "        self.tokenizer =  tokenizer\n",
    "        self.items = items\n",
    "  \n",
    "    def __getitem__(self, index):\n",
    "        content, labels = self.items[index][\"content\"], self.items[index][\"labels\"]\n",
    "        encodings = self.tokenizer(str(content), max_length=512, truncation=True, return_tensors=\"pt\")\n",
    "        for k, v in encodings.items():\n",
    "            encodings[k] = v\n",
    "        return encodings, torch.as_tensor([labels])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "    \n",
    "tokenizer = BertTokenizer.from_pretrained(pretrained_model_dir)\n",
    "eval_dataloader = EvalDataset(\n",
    "        items=val_items,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "model = DiscriminationPredictionEval.from_pretrained(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 在测试集上评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_results(pres, golds):\n",
    "    logits = torch.as_tensor(pres)\n",
    "    labels = torch.as_tensor(golds)\n",
    "    ret = {\n",
    "        \"mae\": MAE(logits, labels).tolist(),\n",
    "        \"mse\": mean_squared_error(golds,  pres),\n",
    "        \"rmse\": np.sqrt(mean_squared_error(golds,  pres)),\n",
    "        \"pcc\": PCC(logits, labels).tolist(),\n",
    "        \"scc\": SCC(logits, labels).tolist(),\n",
    "        'ndcg @all, @10, @20, @30': testdata_metrics(golds, pres).tolist(),\n",
    "    }\n",
    "    return ret\n",
    "\n",
    "model.eval()\n",
    "pred_list = []\n",
    "label_list = []\n",
    "for i, eval_batch in tqdm.tqdm(enumerate(eval_dataloader)):\n",
    "    input_data, eval_batch_labels = eval_batch\n",
    "    output_logits = model(**input_data)\n",
    "    pred_list.append(output_logits.squeeze(0).tolist()[0])\n",
    "    label_list.append(eval_batch_labels.tolist()[0])\n",
    "\n",
    "results = get_eval_results(pred_list, label_list)\n",
    "print(f\"Test results: {results}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tgen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
